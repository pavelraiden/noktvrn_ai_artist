"""
Tests for the ProfileEvolutionManager class.

Uses pytest and pytest-asyncio.
Mocks the LLMOrchestrator and DatabaseConnectionManager interactions.
"""

import pytest
import sys  # Added
import os  # Added
from unittest.mock import patch, AsyncMock  # Removed MagicMock

# --- Add project root to sys.path for imports ---
# Assuming tests are run from a directory where this relative path works
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.append(PROJECT_ROOT)

# Adjust import path based on actual project structure
# This assumes the tests directory is at the same level as the main package directory
# If not, adjust the path accordingly.
try:
    from llm_orchestrator.orchestrator import (
        LLMOrchestrator,
        LLMOrchestratorError,
    )
    from llm_orchestrator.profile_evolution_manager import (
        ProfileEvolutionManager,
    )
    from database.database_connection_manager import DatabaseConnectionManager
except ImportError as e:
    print(f"Import Error: {e}. Check PYTHONPATH and project structure.")

    # Fallback for potential path issues during testing setup
    # This might indicate a problem with how tests are being discovered or run.
    # For now, define dummy classes to allow tests to be parsed.
    class LLMOrchestrator:
        pass

    class LLMOrchestratorError(Exception):
        pass

    class ProfileEvolutionManager:
        def __init__(self, db_manager):
            pass

    class DatabaseConnectionManager:
        pass


# Mock environment variables needed by LLMOrchestrator
@pytest.fixture(autouse=True)
def mock_env_vars(monkeypatch):
    monkeypatch.setenv("OPENAI_API_KEY", "test_api_key")
    monkeypatch.setenv("OPENAI_MODEL_NAME", "gpt-test-model")
    # Add other env vars if ProfileEvolutionManager or its dependencies need them


@pytest.fixture
def mock_db_manager():
    """Provides a mock DatabaseConnectionManager and its cursor."""
    manager = AsyncMock(spec=DatabaseConnectionManager)
    conn = AsyncMock()
    cur = AsyncMock()
    # Configure the async context managers
    manager.get_connection.return_value.__aenter__.return_value = conn
    conn.cursor.return_value.__aenter__.return_value = cur
    # Ensure fetchone returns a tuple or None
    cur.fetchone.return_value = None  # Default to None
    # Ensure rowcount is available
    cur.rowcount = -1  # Default
    return manager, cur  # Return manager and cursor for setting expectations


@pytest.fixture
def mock_llm_orchestrator():
    """Provides a mock LLMOrchestrator instance."""
    # Use spec=LLMOrchestrator to ensure the mock has the correct methods
    orchestrator_instance = AsyncMock(spec=LLMOrchestrator)
    # Set default return values if needed
    orchestrator_instance.evolve_description.return_value = (
        "Mocked Evolved Description"
    )
    return orchestrator_instance


@pytest.fixture
@patch(
    "llm_orchestrator.profile_evolution_manager.LLMOrchestrator"
)  # Patch where it's imported
def profile_evolver(
    MockLLMOrchestratorClass,  # The patched class
    mock_db_manager,
    mock_llm_orchestrator,  # The instance fixture
):
    """Provides an instance of ProfileEvolutionManager with mocked dependencies."""
    # Configure the mock LLMOrchestrator class to return our instance fixture
    MockLLMOrchestratorClass.return_value = mock_llm_orchestrator
    db_manager, _ = mock_db_manager
    # Ensure ProfileEvolutionManager is properly instantiated
    try:
        manager = ProfileEvolutionManager(db_manager=db_manager)
    except NameError:
        # Fallback if import failed earlier
        class DummyProfileEvolutionManager:
            def __init__(self, db_manager):
                self.db_manager = db_manager
                # Add mock methods needed for tests if the real class isn't available
                self.evolve_artist_profile_description = AsyncMock(
                    return_value=None
                )

        manager = DummyProfileEvolutionManager(db_manager=db_manager)

    return manager


@pytest.mark.asyncio
async def test_evolve_description_success(
    profile_evolver, mock_db_manager, mock_llm_orchestrator
):
    """Test successful description evolution including DB fetch and update."""
    db_manager, mock_cursor = mock_db_manager
    artist_id = "artist_test_1"
    current_desc = "Old description."
    goal = "Make it new."
    evolved_desc = "New description generated by LLM."

    # Mock DB fetch
    mock_cursor.fetchone.return_value = (current_desc,)
    # Mock LLM call
    mock_llm_orchestrator.evolve_description.return_value = evolved_desc
    # Mock DB update success
    mock_cursor.rowcount = 1

    result = await profile_evolver.evolve_artist_profile_description(
        artist_id, goal
    )

    assert result == evolved_desc
    # Verify DB fetch call (using more robust check)
    fetch_sql = "SELECT profile ->> 'description' FROM artist_profiles WHERE artist_id = %s;"
    mock_cursor.execute.assert_any_call(fetch_sql, (artist_id,))

    # Verify LLM call
    mock_llm_orchestrator.evolve_description.assert_awaited_once_with(
        current_description=current_desc,
        evolution_goal=goal,
        context=None,  # Assuming no context passed in this test
        max_tokens=512,  # Check against default or expected value
        temperature=0.8,  # Check against default or expected value
    )
    # Verify DB update call (using more robust check)
    update_sql_start = (
        "UPDATE artist_profiles SET profile = jsonb_set(profile,"
    )
    update_call_found = False
    for call in mock_cursor.execute.call_args_list:
        args, kwargs = call
        if (
            args
            and isinstance(args[0], str)
            and args[0].strip().startswith(update_sql_start)
        ):
            assert args[1] == (f'"{evolved_desc}"', artist_id)
            update_call_found = True
            break
    assert update_call_found, "DB update call not found or had wrong arguments"


@pytest.mark.asyncio
async def test_evolve_description_fetch_fails(
    profile_evolver, mock_db_manager, mock_llm_orchestrator
):
    """Test evolution fails if fetching current description fails."""
    db_manager, mock_cursor = mock_db_manager
    artist_id = "artist_test_2"
    goal = "Make it new."

    # Mock DB fetch failure (returns None)
    mock_cursor.fetchone.return_value = None

    result = await profile_evolver.evolve_artist_profile_description(
        artist_id, goal
    )

    assert result is None
    # LLM should not be called
    mock_llm_orchestrator.evolve_description.assert_not_awaited()
    # Verify fetch was attempted
    fetch_sql = "SELECT profile ->> 'description' FROM artist_profiles WHERE artist_id = %s;"
    mock_cursor.execute.assert_any_call(fetch_sql, (artist_id,))


@pytest.mark.asyncio
async def test_evolve_description_llm_fails(
    profile_evolver, mock_db_manager, mock_llm_orchestrator
):
    """Test evolution fails if the LLM call fails."""
    db_manager, mock_cursor = mock_db_manager
    artist_id = "artist_test_3"
    current_desc = "Old description."
    goal = "Make it new."

    # Mock DB fetch success
    mock_cursor.fetchone.return_value = (current_desc,)
    # Mock LLM call failure
    mock_llm_orchestrator.evolve_description.side_effect = (
        LLMOrchestratorError("LLM API Error")
    )

    result = await profile_evolver.evolve_artist_profile_description(
        artist_id, goal
    )

    assert result is None
    mock_llm_orchestrator.evolve_description.assert_awaited_once()  # LLM was called
    # Verify DB update was NOT called
    update_sql_start = (
        "UPDATE artist_profiles SET profile = jsonb_set(profile,"
    )
    update_call_found = False
    for call in mock_cursor.execute.call_args_list:
        args, kwargs = call
        if (
            args
            and isinstance(args[0], str)
            and args[0].strip().startswith(update_sql_start)
        ):
            update_call_found = True
            break
    assert not update_call_found, "DB update call should not have been made"


@pytest.mark.asyncio
async def test_evolve_description_db_update_fails(
    profile_evolver, mock_db_manager, mock_llm_orchestrator
):
    """Test evolution returns description but logs error if DB update fails."""
    db_manager, mock_cursor = mock_db_manager
    artist_id = "artist_test_4"
    current_desc = "Old description."
    goal = "Make it new."
    evolved_desc = "New description generated by LLM."

    # Mock DB fetch success
    mock_cursor.fetchone.return_value = (current_desc,)
    # Mock LLM call success
    mock_llm_orchestrator.evolve_description.return_value = evolved_desc
    # Mock DB update failure (rowcount = 0)
    mock_cursor.rowcount = 0  # Simulate no rows updated

    # Capture logs (requires logger configuration in test setup or conftest.py)
    # For simplicity, we just check the return value and call counts here.

    result = await profile_evolver.evolve_artist_profile_description(
        artist_id, goal
    )

    # Still returns the description, but an error should be logged
    assert result == evolved_desc
    mock_llm_orchestrator.evolve_description.assert_awaited_once()
    # Verify DB update was attempted
    update_sql_start = (
        "UPDATE artist_profiles SET profile = jsonb_set(profile,"
    )
    update_call_found = False
    for call in mock_cursor.execute.call_args_list:
        args, kwargs = call
        if (
            args
            and isinstance(args[0], str)
            and args[0].strip().startswith(update_sql_start)
        ):
            update_call_found = True
            break
    assert update_call_found, "DB update call should have been attempted"
