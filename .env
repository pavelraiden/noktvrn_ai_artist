SUNO_API_KEY="6434df466fc04e16bc1b56eb763bfe6e"
PEXELS_API_KEY="vvQucvzlZ6vLo6RDbrCahvI4gdsW8mgWTVGXyFvPtiI8YAarPK2LFtcm"
PIXABAY_API_KEY="49941633-74bb08eeab74756d08e7ba75a"
DEEPSEEK_API_KEY="sk-efc74f32e9a04b68a785d28c6466f385"
GEMINI_API_KEY="AIzaSyDwkubOj3JEl4P8BK_f-HDoebzO-LCokXI"
GROK_API_KEY="xai-dc9ri9l823T1BbpwZYCJEuV46KBEhXW1cJGEmEMFzc4hz5nbOjl66QhjFGDqoE856rqpIp5ENhxxbhpW"
MISTRAL_API_KEY="hOIujZigJdrr4qKEOrm0rYX8Ddej39ww"
TELEGRAM_BOT_TOKEN="7806913313:AAGO_SUlQCVDQLlW7_lLcUb2gDW2MCIFASY"
TELEGRAM_CHAT_ID="446260424"
# OPENAI_API_KEY="YOUR_OPENAI_API_KEY" # Optional
# ANTHROPIC_API_KEY="YOUR_ANTHROPIC_API_KEY" # Optional, needed for Claude models

# --- General Config ---
LOG_LEVEL="INFO"
OUTPUT_BASE_DIR="/home/ubuntu/ai_artist_system_clone/output"

# --- Batch Runner Config ---
BATCH_POLLING_INTERVAL_SECONDS=60
BATCH_MAX_WAIT_TIME_SECONDS=3600 # 1 hour

# --- Release Chain Config ---
RELEASE_LOG_FILE="/home/ubuntu/ai_artist_system_clone/output/release_log.md"
RELEASE_QUEUE_FILE="/home/ubuntu/ai_artist_system_clone/output/release_queue.json"



# --- Batch Runner Config (Continued) ---
MAX_APPROVAL_WAIT_TIME=300 # Max seconds to wait for Telegram approval
POLL_INTERVAL=10 # Seconds between checking Telegram approval status
REFLECTION_LLM_PRIMARY="deepseek:deepseek-chat" # Primary LLM for generating reflections
REFLECTION_LLM_FALLBACKS="gemini:gemini-pro" # Comma-separated fallback LLMs for reflections
REFLECTION_MAX_TOKENS=500
REFLECTION_TEMPERATURE=0.6
ARTIST_RETIREMENT_THRESHOLD=5 # Consecutive rejections before retiring an artist
ARTIST_CREATION_PROBABILITY=0.1 # Probability (0.0 to 1.0) of creating a new artist each cycle
AB_TESTING_ENABLED="False" # Enable A/B testing framework in batch runner

# --- Error Analysis Service Config ---
ERROR_ANALYSIS_LLM_PRIMARY="deepseek:deepseek-chat" # Primary LLM for analyzing errors
ERROR_ANALYSIS_LLM_FALLBACKS="gemini:gemini-pro" # Comma-separated fallback LLMs for error analysis
ERROR_ANALYSIS_MAX_TOKENS=1000
ERROR_ANALYSIS_TEMPERATURE=0.5
ENGINEER_LLM_PRIMARY="deepseek:deepseek-coder" # Primary LLM for generating fixes (code-focused model recommended)
ENGINEER_LLM_FALLBACKS="gemini:gemini-pro" # Comma-separated fallback LLMs for fix generation
ENGINEER_MAX_TOKENS=1500
ENGINEER_TEMPERATURE=0.3
AUTO_FIX_ENABLED="False" # Enable attempting to auto-apply suggested patches via 'git apply'
MONITOR_INTERVAL_SECONDS=60 # How often the error analysis service checks the log file
ERROR_CONTEXT_LINES=20 # Number of lines before an error to include in analysis context

